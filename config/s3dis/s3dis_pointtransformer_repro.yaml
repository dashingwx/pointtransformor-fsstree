DATA:
  data_name: s3dis
  data_root: dataset/s3dis/trainval_fullarea  # 可保持符号链接或直接路径
  test_area: 5
  classes: 13
  fea_dim: 6  # xyz+rgb
  voxel_size: 0.04  # 保持原分辨率
  voxel_max: 80000  # H20大显存可适当调大，如100000（视内存占用）
  loop: 30  # 数据增强循环次数

TRAIN:
  arch: pointtransformer_seg_repro
  use_xyz: True
  sync_bn: False  # 单卡训练无需跨卡同步BN
  ignore_label: 255
  train_gpu: [0]  # 单卡训练，仅用GPU 0
  workers: 16  # 与16核CPU匹配，最大化数据加载效率
  batch_size: 24 # 单卡batch_size，H20 96GB显存可支持（若溢出可降至32）
  batch_size_val: 16  # 验证时batch_size，利用大显存加速验证
  base_lr: 0.02  # 总batch_size=64（单卡），与之前4卡总批量64保持一致，学习率不变
  epochs: 50  # 保持原epoch数
  start_epoch: 0
  step_epoch: 30  # 30epoch后学习率衰减
  multiplier: 0.1  # 衰减系数（×0.1）
  momentum: 0.9  # 动量参数不变
  weight_decay: 0.0001  # 权重衰减不变
  drop_rate: 0.5  #  dropout保持
  manual_seed: 7777
  print_freq: 10  # 每10步打印一次，减少IO开销
  save_freq: 5  # 每5epoch存一次模型
  save_path: exp/s3dis/pointtransformer_h20  # 新路径避免覆盖
  weight:  # 不加载预训练，从头训练
  resume:  # 不续训
  evaluate: True  # 保留验证
  eval_freq: 5  # 每5epoch验证一次，减少耗时

# 单卡训练，关闭分布式配置
Distributed:
  dist_url: tcp://localhost:8888
  dist_backend: 'nccl'
  multiprocessing_distributed: False  # 关键：单卡关闭分布式
  world_size: 1
  rank: 0

TEST:
  test_list: dataset/s3dis/list/val5.txt
  test_list_full: dataset/s3dis/list/val5.txt
  # test_list_full: dataset/s3dis/list/val5_full.txt # no file
  split: val
  test_gpu: [0]  # 单卡测试
  test_workers: 8  # 测试数据加载线程
  batch_size_test: 24  # 测试batch_size，利用大显存
  model_path:  # 训练完成后自动加载最佳模型
  save_folder:
  names_path: data/s3dis/s3dis_names.txt